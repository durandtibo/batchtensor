{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":""},{"location":"#api-stability","title":"API stability","text":"<p> While <code>batchtensor</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>batchtensor</code> to a new version will possibly break any code that was using the old version of <code>batchtensor</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>batchtensor</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-pip-recommended","title":"Installing with <code>pip</code> (recommended)","text":"<p>The following command installs the latest version of the library:</p> <pre><code>pip install batchtensor\n</code></pre> <p>To make the package as slim as possible, only the packages required to use <code>batchtensor</code> are installed. It is possible to install all the optional dependencies by running the following command:</p> <pre><code>pip install 'batchtensor[all]'\n</code></pre> <p>This command also installed NumPy and PyTorch. It is also possible to install the optional packages manually or to select the packages to install. In the following example, only NumPy is installed:</p> <pre><code>pip install batchtensor numpy\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>batchtensor</code> from source, you can follow the steps below. First, you will need to install <code>poetry</code>. <code>poetry</code> is used to manage and install the dependencies. If <code>poetry</code> is already installed on your machine, you can skip this step. There are several ways to install <code>poetry</code> so you can use the one that you prefer. You can check the <code>poetry</code> installation by running the following command:</p> <pre><code>poetry --version\n</code></pre> <p>Then, you can clone the git repository:</p> <pre><code>git clone git@github.com:durandtibo/batchtensor.git\n</code></pre> <p>It is recommended to create a Python 3.8+ virtual environment. This step is optional so you can skip it. To create a virtual environment, you can use the following command:</p> <pre><code>make conda\n</code></pre> <p>It automatically creates a conda virtual environment. When the virtual environment is created, you can activate it with the following command:</p> <pre><code>conda activate batchtensor\n</code></pre> <p>This example uses <code>conda</code> to create a virtual environment, but you can use other tools or configurations. Then, you should install the required package to use <code>batchtensor</code> with the following command:</p> <pre><code>make install\n</code></pre> <p>This command will install all the required packages. You can also use this command to update the required packages. This command will check if there is a more recent package available and will install it. Finally, you can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre>"},{"location":"refs/tensor/","title":"Tensor","text":""},{"location":"refs/tensor/#batchtensor.tensor","title":"batchtensor.tensor","text":"<p>Contain functions to manipulate tensors.</p>"},{"location":"refs/tensor/#batchtensor.tensor.cat_along_batch","title":"batchtensor.tensor.cat_along_batch","text":"<pre><code>cat_along_batch(\n    tensors: Tensor | Iterable[Tensor],\n) -&gt; Tensor\n</code></pre> <p>Concatenate the given tensors in the batch dimension.</p> <p>All tensors must either have the same data type and shape (except in the concatenating dimension) or be empty.</p> Note <p>This function assumes the batch dimension is the first     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensors</code> <code>Tensor | Iterable[Tensor]</code> <p>Specifies the batches to concatenate.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The concatenated tensors along the batch dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import cat_along_batch\n&gt;&gt;&gt; tensors = [\n...     torch.tensor([[0, 1, 2], [4, 5, 6]]),\n...     torch.tensor([[10, 11, 12], [13, 14, 15]]),\n... ]\n&gt;&gt;&gt; out = cat_along_batch(tensors)\n&gt;&gt;&gt; out\ntensor([[ 0,  1,  2],\n        [ 4,  5,  6],\n        [10, 11, 12],\n        [13, 14, 15]])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.cat_along_seq","title":"batchtensor.tensor.cat_along_seq","text":"<pre><code>cat_along_seq(tensors: Tensor | Iterable[Tensor]) -&gt; Tensor\n</code></pre> <p>Concatenate the given tensors in the sequence dimension.</p> <p>All tensors must either have the same data type and shape (except in the concatenating dimension) or be empty.</p> Note <p>This function assumes the sequence dimension is the second     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensors</code> <code>Tensor | Iterable[Tensor]</code> <p>Specifies the batches to concatenate.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The concatenated tensors along the sequence dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import cat_along_seq\n&gt;&gt;&gt; tensors = [\n...     torch.tensor([[0, 1, 2], [4, 5, 6]]),\n...     torch.tensor([[10, 11], [12, 13]]),\n... ]\n&gt;&gt;&gt; out = cat_along_seq(tensors)\n&gt;&gt;&gt; out\ntensor([[ 0,  1,  2, 10, 11],\n        [ 4,  5,  6, 12, 13]])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.index_select_along_batch","title":"batchtensor.tensor.index_select_along_batch","text":"<pre><code>index_select_along_batch(\n    input: Tensor, index: Tensor\n) -&gt; Tensor\n</code></pre> <p>Return a new tensor which indexes the <code>input</code> tensor along the batch dimension using the entries in <code>index</code> which is a <code>LongTensor</code>.</p> Note <p>This function assumes the batch dimension is the first     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>index</code> <code>Tensor</code> <p>The 1-D tensor containing the indices to index.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The indexed tensor along the batch dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import index_select_along_batch\n&gt;&gt;&gt; tensor = torch.arange(10).view(5, 2)\n&gt;&gt;&gt; index_select_along_batch(tensor, torch.tensor([2, 4]))\ntensor([[4, 5],\n        [8, 9]])\n&gt;&gt;&gt; index_select_along_batch(tensor, torch.tensor([4, 3, 2, 1, 0]))\ntensor([[8, 9],\n        [6, 7],\n        [4, 5],\n        [2, 3],\n        [0, 1]])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.index_select_along_seq","title":"batchtensor.tensor.index_select_along_seq","text":"<pre><code>index_select_along_seq(\n    input: Tensor, index: Tensor\n) -&gt; Tensor\n</code></pre> <p>Return a new tensor which indexes the <code>input</code> tensor along the sequence dimension using the entries in <code>index</code> which is a <code>LongTensor</code>.</p> Note <p>This function assumes the sequence dimension is the second     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Tensor</code> <p>The input tensor.</p> required <code>index</code> <code>Tensor</code> <p>The 1-D tensor containing the indices to index.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The indexed tensor along the sequence dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import index_select_along_seq\n&gt;&gt;&gt; tensor = torch.arange(10).view(2, 5)\n&gt;&gt;&gt; index_select_along_seq(tensor, torch.tensor([2, 4]))\ntensor([[2, 4],\n        [7, 9]])\n&gt;&gt;&gt; index_select_along_seq(tensor, torch.tensor([4, 3, 2, 1, 0]))\ntensor([[4, 3, 2, 1, 0],\n        [9, 8, 7, 6, 5]])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.select_along_batch","title":"batchtensor.tensor.select_along_batch","text":"<pre><code>select_along_batch(tensor: Tensor, index: int) -&gt; Tensor\n</code></pre> <p>Slice the input tensor along the batch dimension at the given index.</p> <p>This function returns a view of the original tensor with the batch dimension removed.</p> Note <p>This function assumes the batch dimension is the first     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The input tensor.</p> required <code>index</code> <code>int</code> <p>The index to select with.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The sliced tensor along the batch dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import select_along_batch\n&gt;&gt;&gt; tensor = torch.arange(10).view(5, 2)\n&gt;&gt;&gt; select_along_batch(tensor, index=2)\ntensor([4, 5])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.select_along_seq","title":"batchtensor.tensor.select_along_seq","text":"<pre><code>select_along_seq(tensor: Tensor, index: int) -&gt; Tensor\n</code></pre> <p>Slice the input tensor along the sequence dimension at the given index.</p> <p>This function returns a view of the original tensor with the sequence dimension removed.</p> Note <p>This function assumes the sequence dimension is the first     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The input tensor.</p> required <code>index</code> <code>int</code> <p>The index to select with.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The sliced tensor along the sequence dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import select_along_seq\n&gt;&gt;&gt; tensor = torch.arange(10).view(2, 5)\n&gt;&gt;&gt; select_along_seq(tensor, index=2)\ntensor([2, 7])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.slice_along_batch","title":"batchtensor.tensor.slice_along_batch","text":"<pre><code>slice_along_batch(\n    tensor: Tensor,\n    start: int = 0,\n    stop: int | None = None,\n    step: int = 1,\n) -&gt; Tensor\n</code></pre> <p>Slice the tensor along the batch dimension.</p> Note <p>This function assumes the batch dimension is the first     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The input tensor.</p> required <code>start</code> <code>int</code> <p>Specifies the index where the slicing of object starts.</p> <code>0</code> <code>stop</code> <code>int | None</code> <p>Specifies the index where the slicing of object stops. <code>None</code> means last.</p> <code>None</code> <code>step</code> <code>int</code> <p>Specifies the increment between each index for slicing.</p> <code>1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The sliced tensor along the batch dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import slice_along_batch\n&gt;&gt;&gt; tensor = torch.arange(10).view(5, 2)\n&gt;&gt;&gt; slice_along_batch(tensor, start=2)\ntensor([[4, 5],\n        [6, 7],\n        [8, 9]])\n&gt;&gt;&gt; slice_along_batch(tensor, stop=3)\ntensor([[0, 1],\n        [2, 3],\n        [4, 5]])\n&gt;&gt;&gt; slice_along_batch(tensor, step=2)\ntensor([[0, 1],\n        [4, 5],\n        [8, 9]])\n</code></pre>"},{"location":"refs/tensor/#batchtensor.tensor.slice_along_seq","title":"batchtensor.tensor.slice_along_seq","text":"<pre><code>slice_along_seq(\n    tensor: Tensor,\n    start: int = 0,\n    stop: int | None = None,\n    step: int = 1,\n) -&gt; Tensor\n</code></pre> <p>Slice the tensor along the sequence dimension.</p> Note <p>This function assumes the sequence dimension is the second     dimension.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The input tensor.</p> required <code>start</code> <code>int</code> <p>Specifies the index where the slicing of object starts.</p> <code>0</code> <code>stop</code> <code>int | None</code> <p>Specifies the index where the slicing of object stops. <code>None</code> means last.</p> <code>None</code> <code>step</code> <code>int</code> <p>Specifies the increment between each index for slicing.</p> <code>1</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The sliced tensor along the sequence dimension.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from batchtensor.tensor import slice_along_seq\n&gt;&gt;&gt; tensor = torch.tensor([[0, 1, 2, 3, 4], [9, 8, 7, 6, 5]])\n&gt;&gt;&gt; slice_along_seq(tensor, start=2)\ntensor([[2, 3, 4],\n        [7, 6, 5]])\n&gt;&gt;&gt; slice_along_seq(tensor, stop=3)\ntensor([[0, 1, 2],\n        [9, 8, 7]])\n&gt;&gt;&gt; slice_along_seq(tensor, step=2)\ntensor([[0, 2, 4],\n        [9, 7, 5]])\n</code></pre>"}]}